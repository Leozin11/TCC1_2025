
Título: On Evaluating the Efficiency of Source Code Generated by LLMs

Referência completa: 
Niu, C., Zhang, T., Li, C., Luo, B., & Ng, V. (2024). On Evaluating the Efficiency of Source Code Generated by LLMs. In *AI Foundation Models and Software Engineering (FORGE '24)*, April 14, 2024, Lisbon, Portugal. ACM. https://doi.org/10.1145/3650105.3652295

Fichamento de Conteúdo

O estudo avalia a eficiência do código gerado por grandes modelos de linguagem (LLMs) como GPT-4, GPT-3.5 e Code Llama. Os autores analisaram o tempo de execução dos códigos utilizando benchmarks como HumanEval, MBPP e o novo conjunto LeetCodeEval, propondo métricas para normalizar esses tempos. Além da performance, investigaram diferentes estratégias de prompts para melhorar a eficiência. Os resultados mostram que a eficiência não depende diretamente da correção funcional nem do tamanho do modelo, e que prompts encadeados podem melhorar significativamente o desempenho do código gerado.

Fichamento Bibliográfico

1. Eficiência de código: medida baseada no tempo médio de execução dos programas gerados (p. 2).
2. Pass@10: métrica que indica a probabilidade de pelo menos um entre dez códigos gerados ser totalmente correto (p. 2).
3. LeetCodeEval: novo benchmark com problemas reais de programação para testar precisão e eficiência (p. 3).
4. gem5: simulador de CPU usado para executar os códigos e reduzir ruído experimental (p. 3).
5. Prompt Engineering: método de elaboração de instruções para otimizar os resultados da IA (p. 4).
6. Prompt encadeado: estratégia que guia o modelo por etapas, levando à geração de código mais eficiente (p. 5).

Fichamento de Citações

1. “Efficiency of LLM-generated code is independent of correctness and model size.” (p. 2)  
2. “Step-by-step prompting could make LLMs generate more efficient code, especially on complex problems.” (p. 5)  
3. “We utilize the gem5 CPU simulator, which is the mostly used golden standard in both academia and industry.” (p. 3)  
4. “GPT-3.5 outperforms GPT-4 in terms of runtime, despite having lower Pass@10.” (p. 4)  
5. “Training strategy and data have an impact on the efficiency of the generated code.” (p. 4)

